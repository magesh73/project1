{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magesh73/project1/blob/master/EVA_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peCsP-TLcsCx",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement:** Below is DNN algorithm to identify numerical images 0..10 and catigorize them according, the algorithm has glitchs that needs to be identified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK4jvtzQ6_TN",
        "colab_type": "text"
      },
      "source": [
        "**Install Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FCzwFrx7GCL",
        "colab_type": "text"
      },
      "source": [
        "**Prerequistes**\n",
        "\n",
        "Keras Models\n",
        "\n",
        "Keras Layers(Covolution2D and Flatten)\n",
        "\n",
        "Keras Utils\n",
        "\n",
        "Dataset -Mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1rJuNwp8JIg",
        "colab_type": "text"
      },
      "source": [
        "Import **trainning** and **test** data from mnist dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5roX9BqV8pdJ",
        "colab_type": "text"
      },
      "source": [
        "Check out the  size/dimension of the train data and using matplotlib library show  image of mnist data\n",
        "\n",
        "Size of the image is **28x28** and we have **60000** samples in training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "83e5a79f-6fbb-48a0-b745-19ee593505ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "for index in range(3):\n",
        "  #define subplot\n",
        "  plt.subplot(330 + 1 + index)\n",
        "  #plot \n",
        "  plt.imshow(X_train[index])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAABiCAYAAADp7+D1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im5CXndI-DvV",
        "colab_type": "text"
      },
      "source": [
        "Reshape the dataset to have single color channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XVXgLUCDafR",
        "colab_type": "text"
      },
      "source": [
        "Currently the pixels as a value between 0-255 unsigned integers, 0 represents bright black color and 255 represents bright white color.\n",
        "\n",
        "For the Model, Normalize/Rescale the pixels values so that they have float values between [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting integer to float value\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Values rescaled to fall between [0,1]\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97TvzzqdbIrS",
        "colab_type": "text"
      },
      "source": [
        "y_train is one dimensional array which has 60000 data samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "5d97a37d-1531-4fbe-b074-bd018a75bfb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjhsHA8qchoF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4XiiTtydnB0",
        "colab_type": "text"
      },
      "source": [
        "As we have 10 catgories [0,1,2,3,4,5,6,7,8,9] of numerical values, we have to classify the images into those categories, the catgories has to be converted into binary values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm5NzWiSx9bL",
        "colab_type": "text"
      },
      "source": [
        "Execute below cell to see the output of category representation in binary value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "4ce1bf5b-4cdd-4952-b91b-6c1a703ae5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbgDO-AhDNFt",
        "colab_type": "code",
        "outputId": "6ff8b480-2c33-4f18-d8ff-19333099e192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "#Input channel 32\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "#Input channel 64\n",
        "#Global Receptive field 5\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "#Input channel 128\n",
        "#Global Receptive field 7\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Input channel 256\n",
        "#Global Receptive field 9\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "#Input channel 512\n",
        "#Global Receptive field 11\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "#Input channel 1024\n",
        "#Global Receptive field 13\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "#Input channel  2048\n",
        "#Global Receptive field 15\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "#Input channel 10\n",
        "#Global Receptive field 17\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "d2dac41f-7f50-47c0-87a4-396e46c07585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "cb031f0c-c998-4fe9-b7a4-fff301a9cc2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23008/60000 [==========>...................] - ETA: 1:22:01 - loss: 14.5087 - acc: 0.0977"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "37248ed8-b523-46b5-cdc6-7589294f25ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05815092300456736, 0.987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "fe6e760c-bbf9-4d1d-c7be-e1cc8e170653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.98473961e-12 6.17699200e-15 1.13075369e-12 2.34764208e-10\n",
            "  1.12143478e-15 5.46381313e-15 1.73773702e-19 1.00000000e+00\n",
            "  2.06114271e-12 1.18310806e-10]\n",
            " [2.99216421e-15 1.22033106e-10 1.00000000e+00 7.20199250e-15\n",
            "  8.06395179e-20 2.24378137e-23 5.75024943e-18 9.92448453e-17\n",
            "  4.74801883e-16 1.10822052e-17]\n",
            " [5.48156301e-13 9.99999881e-01 1.14312769e-11 1.24563090e-16\n",
            "  6.66377531e-08 5.47926064e-14 5.59705683e-14 2.29220154e-09\n",
            "  5.26823333e-12 1.44701674e-13]\n",
            " [1.00000000e+00 7.07125602e-14 6.97996825e-12 1.30143368e-14\n",
            "  7.96424931e-15 1.34024641e-13 1.48142384e-11 2.31121988e-09\n",
            "  6.96624225e-12 5.37044520e-10]\n",
            " [1.51692027e-13 3.60629658e-13 6.29315003e-12 8.01897272e-14\n",
            "  9.99999762e-01 9.91385034e-13 2.58725655e-14 1.79692305e-09\n",
            "  2.33504799e-10 2.88848724e-07]\n",
            " [5.31802080e-14 1.00000000e+00 5.48802106e-12 7.47486591e-17\n",
            "  2.67876554e-10 7.23303850e-18 4.35963060e-19 9.64142277e-09\n",
            "  8.39683618e-12 3.89883351e-12]\n",
            " [4.97652404e-17 9.96331107e-09 4.90022856e-10 1.03960625e-10\n",
            "  9.98863935e-01 4.15669632e-08 1.85732540e-14 6.02729597e-05\n",
            "  9.38676472e-04 1.37069263e-04]\n",
            " [4.58642564e-13 1.34761158e-12 1.82736759e-08 1.02639266e-08\n",
            "  9.06598974e-09 4.24840413e-10 1.87678212e-15 3.47149642e-10\n",
            "  4.39329462e-08 1.00000000e+00]\n",
            " [2.93219051e-12 6.67548651e-17 2.65080380e-15 2.23809469e-13\n",
            "  1.29700506e-14 9.99994040e-01 5.92125161e-06 2.35917496e-16\n",
            "  4.63592364e-09 9.00978181e-11]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aphkWz40Q2L3",
        "colab_type": "text"
      },
      "source": [
        "The usage of the model results in huge parmeters size **25 million**, that is going to be  time consuming operation, and burden on GPU , may be model is using high number of channels and also multiple level of convolution is causing generation of parameters. **bold text**"
      ]
    }
  ]
}